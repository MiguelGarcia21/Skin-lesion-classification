{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10349180,"sourceType":"datasetVersion","datasetId":6408579},{"sourceId":12312908,"sourceType":"datasetVersion","datasetId":7761005},{"sourceId":12323574,"sourceType":"datasetVersion","datasetId":7768001}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Section A: Setup and Imports\n\nThis section sets up the environment for reproducibility and imports all the required libraries, including TensorFlow, Pandas, and image processing utilities. It also sets the random seed and checks GPU availability.","metadata":{}},{"cell_type":"code","source":"import os\nimport random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n\n# Global constants\nIMG_SIZE   = 224\nBATCH_SIZE = 32\nSEED       = 42\n\n# Set random seeds for reproducibility\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)\n\nprint(\"TensorFlow version:\", tf.__version__)\nprint(\"GPUs detected:\", tf.config.list_physical_devices('GPU'))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-29T17:07:39.921842Z","iopub.execute_input":"2025-06-29T17:07:39.922396Z","iopub.status.idle":"2025-06-29T17:07:54.627219Z","shell.execute_reply.started":"2025-06-29T17:07:39.922368Z","shell.execute_reply":"2025-06-29T17:07:54.626519Z"}},"outputs":[{"name":"stderr","text":"2025-06-29 17:07:41.690078: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1751216861.890661      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1751216861.948438      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"TensorFlow version: 2.18.0\nGPUs detected: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"### Section B: Load Metadata and Image Paths\n\nLoads the dataset metadata CSV and constructs full paths to the image files. Invalid or missing entries are filtered, and categorical diagnosis labels are mapped to integers.","metadata":{}},{"cell_type":"code","source":"BASE_RAW = \"/kaggle/input/ham10000-isic2018-raw/dataverse_files\"\nMETA_CSV = os.path.join(BASE_RAW, \"HAM10000_metadata\")\nIMG_DIR  = os.path.join(BASE_RAW, \"HAM10000_images_combined_600x450\")\n\n# 1) Read the metadata table\ndf = pd.read_csv(META_CSV)\n\n# 2) Point each row at its .jpg file\ndf['image_path'] = df['image_id'].apply(lambda x: os.path.join(IMG_DIR, f\"{x}.jpg\"))\n\n# 3) Drop any rows where the file is missing or the diagnosis is missing\nexists_mask = df['image_path'].apply(os.path.exists)\ndf = df[exists_mask].dropna(subset=['dx']).reset_index(drop=True)\nprint(f\"Total images found: {len(df)}\")\n\n# 4) Map the categorical diagnosis ('dx') to numeric labels\nlabel_mapping = {lab: i for i, lab in enumerate(sorted(df['dx'].unique()))}\ndf['label'] = df['dx'].map(label_mapping)\nprint(\"Label → index:\", label_mapping)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T17:07:54.628383Z","iopub.execute_input":"2025-06-29T17:07:54.628831Z","iopub.status.idle":"2025-06-29T17:08:24.977354Z","shell.execute_reply.started":"2025-06-29T17:07:54.628812Z","shell.execute_reply":"2025-06-29T17:08:24.976546Z"}},"outputs":[{"name":"stdout","text":"Total images found: 10015\nLabel → index: {'akiec': 0, 'bcc': 1, 'bkl': 2, 'df': 3, 'mel': 4, 'nv': 5, 'vasc': 6}\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"### Section C: Train/Validation/Test Split\n\nSplits the dataset into training, validation, and test subsets using stratified sampling to maintain class balance. Also tags each sample with its split category.","metadata":{}},{"cell_type":"code","source":"# a) First split off 20% validation+test\ntrain_df, temp_df = train_test_split(\n    df,\n    test_size=0.20,\n    stratify=df['label'],\n    random_state=SEED\n)\n\n# b) Split that 20% into half validation / half test (i.e. 10% each)\nval_df, test_df = train_test_split(\n    temp_df,\n    test_size=0.50,\n    stratify=temp_df['label'],\n    random_state=SEED\n)\n\n# c) Tag them\ntrain_df['split'] = 'train'\nval_df  ['split'] = 'val'\ntest_df ['split'] = 'test'\n\n# d) Re‑concat into one DataFrame if you like:\nmeta = pd.concat([train_df, val_df, test_df], ignore_index=True)\n\n# e) Quick sanity‑check\nprint(\"Images per split:\")\nprint(meta['split'].value_counts(), \"\\n\")\nprint(meta.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T17:08:24.978228Z","iopub.execute_input":"2025-06-29T17:08:24.978654Z","iopub.status.idle":"2025-06-29T17:08:25.014895Z","shell.execute_reply.started":"2025-06-29T17:08:24.978627Z","shell.execute_reply":"2025-06-29T17:08:25.014203Z"}},"outputs":[{"name":"stdout","text":"Images per split:\nsplit\ntrain    8012\ntest     1002\nval      1001\nName: count, dtype: int64 \n\n     lesion_id      image_id     dx    dx_type   age     sex     localization  \\\n0  HAM_0005972  ISIC_0033319     nv      histo  35.0  female  lower extremity   \n1  HAM_0004902  ISIC_0030823     nv  follow_up  40.0    male            trunk   \n2  HAM_0005282  ISIC_0028730  akiec      histo  65.0    male  lower extremity   \n3  HAM_0000475  ISIC_0027299     nv  follow_up  40.0    male  lower extremity   \n4  HAM_0000949  ISIC_0032444     nv      histo  65.0    male             back   \n\n         dataset                                         image_path  label  \\\n0   vidir_modern  /kaggle/input/ham10000-isic2018-raw/dataverse_...      5   \n1  vidir_molemax  /kaggle/input/ham10000-isic2018-raw/dataverse_...      5   \n2      rosendahl  /kaggle/input/ham10000-isic2018-raw/dataverse_...      0   \n3  vidir_molemax  /kaggle/input/ham10000-isic2018-raw/dataverse_...      5   \n4      rosendahl  /kaggle/input/ham10000-isic2018-raw/dataverse_...      5   \n\n   split  \n0  train  \n1  train  \n2  train  \n3  train  \n4  train  \n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"### Section D: Preprocess and Resize Images\n\nResizes all images to a fixed size (`224x224`) using OpenCV and saves them to a working directory. The resized image paths are added to the metadata table.","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom tqdm import tqdm\n\nPROCESSED_DIR = \"/kaggle/working/resized_images\"\nos.makedirs(PROCESSED_DIR, exist_ok=True)\n\ndef preprocess_and_resize(img_path, out_path):\n    img = cv2.imread(img_path)\n    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img_resized = cv2.resize(img_rgb, (IMG_SIZE, IMG_SIZE))\n    img_bgr = cv2.cvtColor(img_resized, cv2.COLOR_RGB2BGR)\n    cv2.imwrite(out_path, img_bgr)\n\n# Process all images and store new path\nmeta[\"resized_filepath\"] = \"\"\nfor idx, row in tqdm(meta.iterrows(), total=len(meta)):\n    out_p = os.path.join(PROCESSED_DIR, os.path.basename(row[\"image_path\"]))\n    preprocess_and_resize(row[\"image_path\"], out_p)\n    meta.at[idx, \"resized_filepath\"] = out_p\n\nprint(\"Resized images saved to:\", PROCESSED_DIR)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T17:08:25.017304Z","iopub.execute_input":"2025-06-29T17:08:25.017578Z","iopub.status.idle":"2025-06-29T17:11:06.674983Z","shell.execute_reply.started":"2025-06-29T17:08:25.017556Z","shell.execute_reply":"2025-06-29T17:11:06.674392Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 10015/10015 [02:41<00:00, 61.96it/s]","output_type":"stream"},{"name":"stdout","text":"Resized images saved to: /kaggle/working/resized_images\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"### Section E: Prepare Final DataFrames by Split\n\nRebuilds `train_df`, `val_df`, and `test_df` DataFrames based on the `split` column, now including the resized image paths.","metadata":{}},{"cell_type":"code","source":"train_df = meta[meta[\"split\"] == \"train\"].reset_index(drop=True)\nval_df   = meta[meta[\"split\"] == \"val\"].reset_index(drop=True)\ntest_df  = meta[meta[\"split\"] == \"test\"].reset_index(drop=True)\n\nprint(f\"Train samples:      {len(train_df)}\")\nprint(f\"Validation samples: {len(val_df)}\")\nprint(f\"Test samples:       {len(test_df)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T17:11:06.675693Z","iopub.execute_input":"2025-06-29T17:11:06.675945Z","iopub.status.idle":"2025-06-29T17:11:06.690409Z","shell.execute_reply.started":"2025-06-29T17:11:06.675919Z","shell.execute_reply":"2025-06-29T17:11:06.689671Z"}},"outputs":[{"name":"stdout","text":"Train samples:      8012\nValidation samples: 1001\nTest samples:       1002\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"### Section F: Image Generators (ResNet Compatible)\n\nPrepares `ImageDataGenerator` pipelines for training, validation, and test data. Applies real-time data augmentation during training to improve generalization. Uses standard rescaling (1./255) for ResNet models.","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Convert label integers to strings for categorical mode\nfor df_ in [train_df, val_df, test_df]:\n    df_['label_str'] = df_['label'].astype(str)\n\n# Training data generator with augmentation\ntrain_aug = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=20,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\n# Validation/Test data generator (no augmentation)\neval_gen = ImageDataGenerator(rescale=1./255)\n\n# Iterators - using resized images and string labels\ntrain_it = train_aug.flow_from_dataframe(\n    train_df,\n    x_col='resized_filepath',\n    y_col='label_str',\n    target_size=(IMG_SIZE, IMG_SIZE),\n    class_mode='categorical',\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    seed=SEED\n)\n\nval_it = eval_gen.flow_from_dataframe(\n    val_df,\n    x_col='resized_filepath',\n    y_col='label_str',\n    target_size=(IMG_SIZE, IMG_SIZE),\n    class_mode='categorical',\n    batch_size=BATCH_SIZE,\n    shuffle=False\n)\n\ntest_it = eval_gen.flow_from_dataframe(\n    test_df,\n    x_col='resized_filepath',\n    y_col='label_str',\n    target_size=(IMG_SIZE, IMG_SIZE),\n    class_mode='categorical',\n    batch_size=BATCH_SIZE,\n    shuffle=False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T17:11:06.691281Z","iopub.execute_input":"2025-06-29T17:11:06.691513Z","iopub.status.idle":"2025-06-29T17:11:06.782753Z","shell.execute_reply.started":"2025-06-29T17:11:06.691496Z","shell.execute_reply":"2025-06-29T17:11:06.782179Z"}},"outputs":[{"name":"stdout","text":"Found 8012 validated image filenames belonging to 7 classes.\nFound 1001 validated image filenames belonging to 7 classes.\nFound 1002 validated image filenames belonging to 7 classes.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"### Section G: Model Architectures (ResNet50 & EfficientNetB0)\n\nDefines two CNN architectures using transfer learning: ResNet50 and EfficientNetB0. Includes support for fine-tuning the last N convolutional blocks. Outputs a softmax layer for multi-class classification.","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import layers, models, optimizers\n\nNUM_CLASSES = train_df['label_str'].nunique()\ndef build_resnet(unfreeze_last_blocks=0):\n    base = tf.keras.applications.ResNet50(\n        include_top=False, weights='imagenet',\n        input_shape=(IMG_SIZE, IMG_SIZE, 3)\n    )\n    base.trainable = False\n    x = layers.GlobalAveragePooling2D()(base.output)\n    x = layers.Dense(128, activation='relu')(x)\n    out = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n    model = models.Model(inputs=base.input, outputs=out)\n    if unfreeze_last_blocks > 0:\n        # Unfreeze the last N convolutional blocks (~10 layers per block)\n        for layer in base.layers[-unfreeze_last_blocks*10:]:\n            layer.trainable = True\n    model.compile(\n        optimizer=optimizers.Adam(),\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\ndef build_efficientnet(unfreeze_last_blocks=0):\n    base = tf.keras.applications.EfficientNetB0(\n        include_top=False, weights='imagenet',\n        input_shape=(IMG_SIZE, IMG_SIZE, 3)\n    )\n    base.trainable = False\n    x = layers.GlobalAveragePooling2D()(base.output)\n    x = layers.Dense(128, activation='relu')(x)\n    out = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n    model = models.Model(inputs=base.input, outputs=out)\n    if unfreeze_last_blocks > 0:\n        for layer in base.layers[-unfreeze_last_blocks*10:]:\n            layer.trainable = True\n    model.compile(\n        optimizer=optimizers.Adam(),\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T17:11:06.783348Z","iopub.execute_input":"2025-06-29T17:11:06.783549Z","iopub.status.idle":"2025-06-29T17:11:06.791213Z","shell.execute_reply.started":"2025-06-29T17:11:06.783533Z","shell.execute_reply":"2025-06-29T17:11:06.790571Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"### Section H: Train ResNet50\n\nTrains ResNet50 in two phases:\n\n1. **Frozen base** (only top layers trainable).\n2. **Fine-tuning** with the last 2 ResNet blocks unfrozen.\n   Includes callbacks for early stopping, learning rate reduction, and checkpoint saving.","metadata":{}},{"cell_type":"code","source":"# Phase 1: frozen\nresnet = build_resnet(unfreeze_last_blocks=0)\ncallbacks_r1 = [\n    tf.keras.callbacks.ModelCheckpoint(\"resnet_frozen.h5\", save_best_only=True),\n    tf.keras.callbacks.ReduceLROnPlateau(patience=5),\n    tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n]\nhistory_r1 = resnet.fit(\n    train_it,\n    validation_data=val_it,\n    epochs=20,\n    callbacks=callbacks_r1,\n    verbose=1\n)\n\n# Phase 2: fine-tuning\nresnet = build_resnet(unfreeze_last_blocks=2)\nresnet.load_weights(\"resnet_frozen.h5\")\ncallbacks_r2 = [\n    tf.keras.callbacks.ModelCheckpoint(\"resnet_ft.h5\", save_best_only=True),\n    tf.keras.callbacks.ReduceLROnPlateau(patience=5),\n    tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n]\nhistory_r2 = resnet.fit(\n    train_it,\n    validation_data=val_it,\n    epochs=30,\n    callbacks=callbacks_r2,\n    verbose=1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T17:11:06.791879Z","iopub.execute_input":"2025-06-29T17:11:06.792104Z","iopub.status.idle":"2025-06-29T18:19:15.729746Z","shell.execute_reply.started":"2025-06-29T17:11:06.792087Z","shell.execute_reply":"2025-06-29T18:19:15.729168Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1751217066.925650      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1751217080.898758     104 service.cc:148] XLA service 0x77fffc003600 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1751217080.899726     104 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1751217082.381099     104 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  2/251\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 55ms/step - accuracy: 0.6016 - loss: 1.4092   ","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1751217085.864643     104 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 361ms/step - accuracy: 0.6701 - loss: 1.1595 - val_accuracy: 0.6693 - val_loss: 1.1407 - learning_rate: 0.0010\nEpoch 2/20\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 321ms/step - accuracy: 0.6680 - loss: 1.1345 - val_accuracy: 0.6683 - val_loss: 1.1151 - learning_rate: 0.0010\nEpoch 3/20\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 320ms/step - accuracy: 0.6746 - loss: 1.1059 - val_accuracy: 0.6693 - val_loss: 1.0976 - learning_rate: 0.0010\nEpoch 4/20\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 324ms/step - accuracy: 0.6655 - loss: 1.1097 - val_accuracy: 0.6703 - val_loss: 1.0919 - learning_rate: 0.0010\nEpoch 5/20\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 319ms/step - accuracy: 0.6699 - loss: 1.0903 - val_accuracy: 0.6703 - val_loss: 1.0705 - learning_rate: 0.0010\nEpoch 6/20\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 317ms/step - accuracy: 0.6769 - loss: 1.0767 - val_accuracy: 0.6703 - val_loss: 1.0749 - learning_rate: 0.0010\nEpoch 7/20\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 320ms/step - accuracy: 0.6643 - loss: 1.0882 - val_accuracy: 0.6683 - val_loss: 1.0501 - learning_rate: 0.0010\nEpoch 8/20\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 319ms/step - accuracy: 0.6754 - loss: 1.0675 - val_accuracy: 0.6703 - val_loss: 1.0431 - learning_rate: 0.0010\nEpoch 9/20\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 318ms/step - accuracy: 0.6725 - loss: 1.0596 - val_accuracy: 0.6703 - val_loss: 1.0428 - learning_rate: 0.0010\nEpoch 10/20\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 316ms/step - accuracy: 0.6772 - loss: 1.0406 - val_accuracy: 0.6733 - val_loss: 1.0447 - learning_rate: 0.0010\nEpoch 11/20\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 314ms/step - accuracy: 0.6748 - loss: 1.0532 - val_accuracy: 0.6723 - val_loss: 1.0621 - learning_rate: 0.0010\nEpoch 12/20\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 318ms/step - accuracy: 0.6823 - loss: 1.0356 - val_accuracy: 0.6733 - val_loss: 1.0273 - learning_rate: 0.0010\nEpoch 13/20\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 322ms/step - accuracy: 0.6777 - loss: 1.0383 - val_accuracy: 0.6733 - val_loss: 1.0365 - learning_rate: 0.0010\nEpoch 14/20\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 320ms/step - accuracy: 0.6719 - loss: 1.0489 - val_accuracy: 0.6723 - val_loss: 1.0252 - learning_rate: 0.0010\nEpoch 15/20\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 322ms/step - accuracy: 0.6834 - loss: 1.0276 - val_accuracy: 0.6753 - val_loss: 1.0307 - learning_rate: 0.0010\nEpoch 16/20\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 323ms/step - accuracy: 0.6790 - loss: 1.0372 - val_accuracy: 0.6753 - val_loss: 1.0170 - learning_rate: 0.0010\nEpoch 17/20\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 316ms/step - accuracy: 0.6686 - loss: 1.0406 - val_accuracy: 0.6663 - val_loss: 1.0419 - learning_rate: 0.0010\nEpoch 18/20\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 317ms/step - accuracy: 0.6727 - loss: 1.0538 - val_accuracy: 0.6743 - val_loss: 1.0245 - learning_rate: 0.0010\nEpoch 19/20\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 319ms/step - accuracy: 0.6836 - loss: 1.0061 - val_accuracy: 0.6733 - val_loss: 1.0156 - learning_rate: 0.0010\nEpoch 20/20\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 319ms/step - accuracy: 0.6805 - loss: 1.0227 - val_accuracy: 0.6763 - val_loss: 1.0226 - learning_rate: 0.0010\nEpoch 1/30\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 367ms/step - accuracy: 0.6640 - loss: 1.1557 - val_accuracy: 0.6713 - val_loss: 2.8060 - learning_rate: 0.0010\nEpoch 2/30\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 328ms/step - accuracy: 0.6677 - loss: 0.9736 - val_accuracy: 0.6663 - val_loss: 14.8636 - learning_rate: 0.0010\nEpoch 3/30\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 326ms/step - accuracy: 0.6676 - loss: 0.9877 - val_accuracy: 0.1109 - val_loss: 7.4403 - learning_rate: 0.0010\nEpoch 4/30\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 324ms/step - accuracy: 0.6701 - loss: 0.9530 - val_accuracy: 0.1109 - val_loss: 3.2113 - learning_rate: 0.0010\nEpoch 5/30\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 320ms/step - accuracy: 0.6745 - loss: 0.9402 - val_accuracy: 0.6693 - val_loss: 12.9450 - learning_rate: 0.0010\nEpoch 6/30\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 338ms/step - accuracy: 0.6790 - loss: 0.9159 - val_accuracy: 0.5445 - val_loss: 1.1288 - learning_rate: 0.0010\nEpoch 7/30\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 321ms/step - accuracy: 0.6937 - loss: 0.8934 - val_accuracy: 0.1109 - val_loss: 5.1294 - learning_rate: 0.0010\nEpoch 8/30\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 328ms/step - accuracy: 0.6718 - loss: 0.9379 - val_accuracy: 0.2587 - val_loss: 1.6668 - learning_rate: 0.0010\nEpoch 9/30\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 321ms/step - accuracy: 0.6911 - loss: 0.8848 - val_accuracy: 0.6703 - val_loss: 1.7977 - learning_rate: 0.0010\nEpoch 10/30\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 322ms/step - accuracy: 0.6793 - loss: 0.8942 - val_accuracy: 0.1249 - val_loss: 1.5407 - learning_rate: 0.0010\nEpoch 11/30\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 322ms/step - accuracy: 0.6816 - loss: 0.8713 - val_accuracy: 0.6723 - val_loss: 1.7067 - learning_rate: 0.0010\nEpoch 12/30\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 322ms/step - accuracy: 0.6917 - loss: 0.8651 - val_accuracy: 0.6653 - val_loss: 1.1078 - learning_rate: 1.0000e-04\nEpoch 13/30\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 317ms/step - accuracy: 0.6984 - loss: 0.8259 - val_accuracy: 0.6464 - val_loss: 1.1951 - learning_rate: 1.0000e-04\nEpoch 14/30\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 322ms/step - accuracy: 0.6990 - loss: 0.8216 - val_accuracy: 0.6793 - val_loss: 1.6051 - learning_rate: 1.0000e-04\nEpoch 15/30\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 318ms/step - accuracy: 0.6928 - loss: 0.8406 - val_accuracy: 0.6783 - val_loss: 1.2982 - learning_rate: 1.0000e-04\nEpoch 16/30\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 321ms/step - accuracy: 0.7064 - loss: 0.8087 - val_accuracy: 0.7023 - val_loss: 0.8512 - learning_rate: 1.0000e-04\nEpoch 17/30\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 318ms/step - accuracy: 0.6973 - loss: 0.8266 - val_accuracy: 0.6523 - val_loss: 0.9927 - learning_rate: 1.0000e-04\nEpoch 18/30\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 318ms/step - accuracy: 0.6978 - loss: 0.8235 - val_accuracy: 0.6484 - val_loss: 0.9497 - learning_rate: 1.0000e-04\nEpoch 19/30\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 315ms/step - accuracy: 0.7021 - loss: 0.8187 - val_accuracy: 0.6963 - val_loss: 0.8590 - learning_rate: 1.0000e-04\nEpoch 20/30\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 326ms/step - accuracy: 0.7041 - loss: 0.8027 - val_accuracy: 0.6204 - val_loss: 1.0164 - learning_rate: 1.0000e-04\nEpoch 21/30\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 323ms/step - accuracy: 0.7076 - loss: 0.8189 - val_accuracy: 0.6424 - val_loss: 1.0476 - learning_rate: 1.0000e-04\nEpoch 22/30\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 319ms/step - accuracy: 0.7050 - loss: 0.8056 - val_accuracy: 0.6963 - val_loss: 0.7988 - learning_rate: 1.0000e-05\nEpoch 23/30\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 317ms/step - accuracy: 0.7050 - loss: 0.8254 - val_accuracy: 0.6963 - val_loss: 0.8266 - learning_rate: 1.0000e-05\nEpoch 24/30\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 317ms/step - accuracy: 0.7104 - loss: 0.7962 - val_accuracy: 0.6953 - val_loss: 0.7995 - learning_rate: 1.0000e-05\nEpoch 25/30\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 318ms/step - accuracy: 0.7067 - loss: 0.8063 - val_accuracy: 0.6963 - val_loss: 0.7996 - learning_rate: 1.0000e-05\nEpoch 26/30\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 317ms/step - accuracy: 0.7169 - loss: 0.7896 - val_accuracy: 0.7043 - val_loss: 0.8080 - learning_rate: 1.0000e-05\nEpoch 27/30\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 316ms/step - accuracy: 0.7043 - loss: 0.8044 - val_accuracy: 0.6953 - val_loss: 0.8527 - learning_rate: 1.0000e-05\nEpoch 28/30\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 318ms/step - accuracy: 0.7193 - loss: 0.7850 - val_accuracy: 0.6983 - val_loss: 0.7959 - learning_rate: 1.0000e-06\nEpoch 29/30\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 328ms/step - accuracy: 0.7050 - loss: 0.8115 - val_accuracy: 0.7013 - val_loss: 0.7951 - learning_rate: 1.0000e-06\nEpoch 30/30\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 323ms/step - accuracy: 0.7117 - loss: 0.7935 - val_accuracy: 0.6993 - val_loss: 0.7971 - learning_rate: 1.0000e-06\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"### Section I: EfficientNet-Compatible Data Generators\n\nCreates separate `ImageDataGenerator` objects using `preprocess_input` from `tensorflow.keras.applications.efficientnet`, which is required for EfficientNetB0. Includes augmentations for training only.","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications.efficientnet import preprocess_input\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Convertir las etiquetas a string para modo categorical\nfor df_ in [train_df, val_df, test_df]:\n    df_['label_str'] = df_['label'].astype(str)\n\n# Generador con augmentación y preprocessing correcto para EfficientNet\ntrain_aug = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n    rotation_range=20,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\n# Generador de validación y test (solo preprocessing)\neval_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n\n# Generadores (ImageDataIterator)\ntrain_it = train_aug.flow_from_dataframe(\n    train_df,\n    x_col='resized_filepath',\n    y_col='label_str',\n    target_size=(IMG_SIZE, IMG_SIZE),\n    class_mode='categorical',\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    seed=SEED\n)\n\nval_it = eval_gen.flow_from_dataframe(\n    val_df,\n    x_col='resized_filepath',\n    y_col='label_str',\n    target_size=(IMG_SIZE, IMG_SIZE),\n    class_mode='categorical',\n    batch_size=BATCH_SIZE,\n    shuffle=False\n)\n\ntest_it = eval_gen.flow_from_dataframe(\n    test_df,\n    x_col='resized_filepath',\n    y_col='label_str',\n    target_size=(IMG_SIZE, IMG_SIZE),\n    class_mode='categorical',\n    batch_size=BATCH_SIZE,\n    shuffle=False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T18:19:15.730778Z","iopub.execute_input":"2025-06-29T18:19:15.730991Z","iopub.status.idle":"2025-06-29T18:19:15.828896Z","shell.execute_reply.started":"2025-06-29T18:19:15.730975Z","shell.execute_reply":"2025-06-29T18:19:15.828208Z"}},"outputs":[{"name":"stdout","text":"Found 8012 validated image filenames belonging to 7 classes.\nFound 1001 validated image filenames belonging to 7 classes.\nFound 1002 validated image filenames belonging to 7 classes.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"### Section J: Train EfficientNetB0\n\nTwo-phase training of EfficientNetB0:\n\n1. **Frozen base** phase with callbacks and learning rate tracking.\n2. **Fine-tuning** with last 2 blocks unfrozen. Uses custom learning rate and callbacks for optimal performance.","metadata":{}},{"cell_type":"code","source":"# Fase 1: Base congelada\neff = build_efficientnet(unfreeze_last_blocks=0)\ncallbacks_e1 = [\n    tf.keras.callbacks.ModelCheckpoint(\"eff_frozen.h5\", save_best_only=True),\n    tf.keras.callbacks.ReduceLROnPlateau(patience=4, factor=0.5, verbose=1),\n    tf.keras.callbacks.EarlyStopping(patience=8, restore_best_weights=True, verbose=1),\n    tf.keras.callbacks.LambdaCallback(\n        on_epoch_end=lambda epoch, logs: print(f\"LR (Phase 1): {eff.optimizer.learning_rate.numpy():.6f}\")\n    )\n]\nhistory_e1 = eff.fit(\n    train_it,\n    validation_data=val_it,\n    epochs=15,\n    callbacks=callbacks_e1,\n    verbose=1\n)\n\n# Fase 2: Fine-tuning (descongelar los últimos 2 bloques)\neff = build_efficientnet(unfreeze_last_blocks=2)\neff.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\neff.load_weights(\"eff_frozen.h5\")\ncallbacks_e2 = [\n    tf.keras.callbacks.ModelCheckpoint(\"eff_ft.h5\", save_best_only=True),\n    tf.keras.callbacks.ReduceLROnPlateau(patience=4, factor=0.5, verbose=1),\n    tf.keras.callbacks.EarlyStopping(patience=8, restore_best_weights=True, verbose=1),\n    tf.keras.callbacks.LambdaCallback(\n        on_epoch_end=lambda epoch, logs: print(f\"LR (Phase 2): {eff.optimizer.learning_rate.numpy():.6f}\")\n    )\n]\nhistory_e2 = eff.fit(\n    train_it,\n    validation_data=val_it,\n    epochs=25,\n    callbacks=callbacks_e2,\n    verbose=1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T18:19:15.830932Z","iopub.execute_input":"2025-06-29T18:19:15.831241Z","iopub.status.idle":"2025-06-29T19:05:14.933978Z","shell.execute_reply.started":"2025-06-29T18:19:15.831222Z","shell.execute_reply":"2025-06-29T19:05:14.933228Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/15\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step - accuracy: 0.7037 - loss: 0.8820LR (Phase 1): 0.001000\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 387ms/step - accuracy: 0.7038 - loss: 0.8817 - val_accuracy: 0.7323 - val_loss: 0.7400 - learning_rate: 0.0010\nEpoch 2/15\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.7570 - loss: 0.6559LR (Phase 1): 0.001000\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 309ms/step - accuracy: 0.7570 - loss: 0.6559 - val_accuracy: 0.7502 - val_loss: 0.6844 - learning_rate: 0.0010\nEpoch 3/15\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.7682 - loss: 0.6150LR (Phase 1): 0.001000\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 311ms/step - accuracy: 0.7682 - loss: 0.6150 - val_accuracy: 0.7622 - val_loss: 0.6423 - learning_rate: 0.0010\nEpoch 4/15\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.7945 - loss: 0.5645LR (Phase 1): 0.001000\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 314ms/step - accuracy: 0.7944 - loss: 0.5645 - val_accuracy: 0.7632 - val_loss: 0.6313 - learning_rate: 0.0010\nEpoch 5/15\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step - accuracy: 0.7992 - loss: 0.5376LR (Phase 1): 0.001000\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 314ms/step - accuracy: 0.7992 - loss: 0.5377 - val_accuracy: 0.7752 - val_loss: 0.6428 - learning_rate: 0.0010\nEpoch 6/15\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.7962 - loss: 0.5422LR (Phase 1): 0.001000\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 311ms/step - accuracy: 0.7962 - loss: 0.5422 - val_accuracy: 0.7622 - val_loss: 0.6284 - learning_rate: 0.0010\nEpoch 7/15\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 0.8153 - loss: 0.4978LR (Phase 1): 0.001000\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 312ms/step - accuracy: 0.8153 - loss: 0.4979 - val_accuracy: 0.7812 - val_loss: 0.6085 - learning_rate: 0.0010\nEpoch 8/15\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - accuracy: 0.8136 - loss: 0.4920LR (Phase 1): 0.001000\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 313ms/step - accuracy: 0.8136 - loss: 0.4920 - val_accuracy: 0.7902 - val_loss: 0.5815 - learning_rate: 0.0010\nEpoch 9/15\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.8275 - loss: 0.4712LR (Phase 1): 0.001000\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 308ms/step - accuracy: 0.8274 - loss: 0.4712 - val_accuracy: 0.7782 - val_loss: 0.6197 - learning_rate: 0.0010\nEpoch 10/15\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.8345 - loss: 0.4585LR (Phase 1): 0.001000\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 309ms/step - accuracy: 0.8344 - loss: 0.4585 - val_accuracy: 0.7822 - val_loss: 0.5967 - learning_rate: 0.0010\nEpoch 11/15\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - accuracy: 0.8498 - loss: 0.4299LR (Phase 1): 0.001000\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 307ms/step - accuracy: 0.8498 - loss: 0.4300 - val_accuracy: 0.7892 - val_loss: 0.5900 - learning_rate: 0.0010\nEpoch 12/15\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.8435 - loss: 0.4307\nEpoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\nLR (Phase 1): 0.000500\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 309ms/step - accuracy: 0.8435 - loss: 0.4308 - val_accuracy: 0.7882 - val_loss: 0.5957 - learning_rate: 0.0010\nEpoch 13/15\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.8500 - loss: 0.4056LR (Phase 1): 0.000500\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 311ms/step - accuracy: 0.8500 - loss: 0.4056 - val_accuracy: 0.8002 - val_loss: 0.5704 - learning_rate: 5.0000e-04\nEpoch 14/15\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310ms/step - accuracy: 0.8623 - loss: 0.3829LR (Phase 1): 0.000500\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 318ms/step - accuracy: 0.8623 - loss: 0.3829 - val_accuracy: 0.7962 - val_loss: 0.5688 - learning_rate: 5.0000e-04\nEpoch 15/15\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.8662 - loss: 0.3752LR (Phase 1): 0.000500\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 311ms/step - accuracy: 0.8662 - loss: 0.3752 - val_accuracy: 0.7982 - val_loss: 0.5481 - learning_rate: 5.0000e-04\nRestoring model weights from the end of the best epoch: 15.\nEpoch 1/25\n","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1751222399.108648     105 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1751222399.316050     105 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m161/251\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m27s\u001b[0m 305ms/step - accuracy: 0.7042 - loss: 0.8596","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1751222458.593187     104 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1751222458.798644     104 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343ms/step - accuracy: 0.7230 - loss: 0.7954LR (Phase 2): 0.000100\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 389ms/step - accuracy: 0.7231 - loss: 0.7949 - val_accuracy: 0.7932 - val_loss: 0.6008 - learning_rate: 1.0000e-04\nEpoch 2/25\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 0.8261 - loss: 0.4710LR (Phase 2): 0.000100\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 313ms/step - accuracy: 0.8261 - loss: 0.4710 - val_accuracy: 0.7882 - val_loss: 0.5825 - learning_rate: 1.0000e-04\nEpoch 3/25\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - accuracy: 0.8493 - loss: 0.4263LR (Phase 2): 0.000100\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 314ms/step - accuracy: 0.8493 - loss: 0.4263 - val_accuracy: 0.8202 - val_loss: 0.5275 - learning_rate: 1.0000e-04\nEpoch 4/25\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310ms/step - accuracy: 0.8591 - loss: 0.3766LR (Phase 2): 0.000100\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 315ms/step - accuracy: 0.8591 - loss: 0.3766 - val_accuracy: 0.8132 - val_loss: 0.5563 - learning_rate: 1.0000e-04\nEpoch 5/25\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.8724 - loss: 0.3538LR (Phase 2): 0.000100\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 314ms/step - accuracy: 0.8724 - loss: 0.3538 - val_accuracy: 0.8222 - val_loss: 0.5171 - learning_rate: 1.0000e-04\nEpoch 6/25\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - accuracy: 0.8798 - loss: 0.3231LR (Phase 2): 0.000100\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 316ms/step - accuracy: 0.8798 - loss: 0.3231 - val_accuracy: 0.8112 - val_loss: 0.5398 - learning_rate: 1.0000e-04\nEpoch 7/25\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step - accuracy: 0.8902 - loss: 0.3027LR (Phase 2): 0.000100\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 314ms/step - accuracy: 0.8902 - loss: 0.3027 - val_accuracy: 0.8142 - val_loss: 0.5174 - learning_rate: 1.0000e-04\nEpoch 8/25\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.9000 - loss: 0.2794LR (Phase 2): 0.000100\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 313ms/step - accuracy: 0.9000 - loss: 0.2794 - val_accuracy: 0.8182 - val_loss: 0.5534 - learning_rate: 1.0000e-04\nEpoch 9/25\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.8999 - loss: 0.2733LR (Phase 2): 0.000100\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 310ms/step - accuracy: 0.8999 - loss: 0.2733 - val_accuracy: 0.8382 - val_loss: 0.4876 - learning_rate: 1.0000e-04\nEpoch 10/25\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.9090 - loss: 0.2446LR (Phase 2): 0.000100\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 309ms/step - accuracy: 0.9090 - loss: 0.2446 - val_accuracy: 0.8242 - val_loss: 0.5064 - learning_rate: 1.0000e-04\nEpoch 11/25\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 0.9169 - loss: 0.2310LR (Phase 2): 0.000100\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 312ms/step - accuracy: 0.9169 - loss: 0.2309 - val_accuracy: 0.8482 - val_loss: 0.4678 - learning_rate: 1.0000e-04\nEpoch 12/25\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 0.9233 - loss: 0.2120LR (Phase 2): 0.000100\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 311ms/step - accuracy: 0.9233 - loss: 0.2120 - val_accuracy: 0.8252 - val_loss: 0.5202 - learning_rate: 1.0000e-04\nEpoch 13/25\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 0.9297 - loss: 0.2034LR (Phase 2): 0.000100\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 311ms/step - accuracy: 0.9297 - loss: 0.2034 - val_accuracy: 0.8272 - val_loss: 0.5230 - learning_rate: 1.0000e-04\nEpoch 14/25\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 0.9307 - loss: 0.1988LR (Phase 2): 0.000100\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 311ms/step - accuracy: 0.9307 - loss: 0.1988 - val_accuracy: 0.8132 - val_loss: 0.5763 - learning_rate: 1.0000e-04\nEpoch 15/25\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.9302 - loss: 0.1891\nEpoch 15: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\nLR (Phase 2): 0.000050\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 308ms/step - accuracy: 0.9302 - loss: 0.1890 - val_accuracy: 0.8352 - val_loss: 0.5145 - learning_rate: 1.0000e-04\nEpoch 16/25\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.9478 - loss: 0.1572LR (Phase 2): 0.000050\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 313ms/step - accuracy: 0.9477 - loss: 0.1573 - val_accuracy: 0.8292 - val_loss: 0.5428 - learning_rate: 5.0000e-05\nEpoch 17/25\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 0.9514 - loss: 0.1489LR (Phase 2): 0.000050\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 310ms/step - accuracy: 0.9514 - loss: 0.1488 - val_accuracy: 0.8412 - val_loss: 0.5360 - learning_rate: 5.0000e-05\nEpoch 18/25\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - accuracy: 0.9403 - loss: 0.1569LR (Phase 2): 0.000050\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 312ms/step - accuracy: 0.9403 - loss: 0.1569 - val_accuracy: 0.8422 - val_loss: 0.5242 - learning_rate: 5.0000e-05\nEpoch 19/25\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 0.9506 - loss: 0.1381\nEpoch 19: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\nLR (Phase 2): 0.000025\n\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 311ms/step - accuracy: 0.9506 - loss: 0.1381 - val_accuracy: 0.8332 - val_loss: 0.5355 - learning_rate: 5.0000e-05\nEpoch 19: early stopping\nRestoring model weights from the end of the best epoch: 11.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"### Section K: Evaluate and Compare Models\n\nLoads the best weights from each model and evaluates performance on the test set. Reports accuracy, weighted F1-score, and detailed classification metrics. Displays a side-by-side comparison in a bar chart.","metadata":{}},{"cell_type":"code","source":"# Prepare comparison\nresults = []\nmodels_info = [\n    (\"ResNet50\", \"resnet_ft.h5\", build_resnet, 2),\n    (\"EfficientNetB0\", \"eff_ft.h5\", build_efficientnet, 2),\n]\n\nfor name, weights, builder, unfreeze in models_info:\n    print(f\"\\nEvaluating model: {name}\")\n    m = builder(unfreeze_last_blocks=unfreeze)\n    m.load_weights(weights)\n    y_pred = m.predict(test_it).argmax(axis=1)\n    y_true = test_it.classes\n    acc = accuracy_score(y_true, y_pred)\n    f1  = f1_score(y_true, y_pred, average='weighted')\n    results.append((name, acc, f1))\n    \n    # Print classification report\n    # Build reverse mapping: label index → original dx string\n    inv_map = {v: k for k, v in label_mapping.items()}\n    target_names = [inv_map[i] for i in sorted(inv_map)]\n    print(classification_report(y_true, y_pred, target_names=target_names))\n\n\n# Display results\ndf_results = pd.DataFrame(results, columns=[\"Model\", \"Accuracy\", \"Weighted F1\"])\ndisplay(df_results)\n\n# Bar chart of accuracies\nplt.figure(figsize=(6,4))\nplt.bar(df_results[\"Model\"], df_results[\"Accuracy\"], color=\"teal\")\nplt.ylim(0,1)\nplt.ylabel(\"Accuracy\")\nplt.title(\"Model Accuracy Comparison\")\nplt.grid(True, linestyle='--', alpha=0.5)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T19:05:14.935150Z","iopub.execute_input":"2025-06-29T19:05:14.935430Z","iopub.status.idle":"2025-06-29T19:05:44.620684Z","shell.execute_reply.started":"2025-06-29T19:05:14.935406Z","shell.execute_reply":"2025-06-29T19:05:44.619878Z"}},"outputs":[{"name":"stdout","text":"\nEvaluating model: ResNet50\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 195ms/step\n              precision    recall  f1-score   support\n\n       akiec       0.00      0.00      0.00        32\n         bcc       0.00      0.00      0.00        52\n         bkl       0.00      0.00      0.00       110\n          df       0.00      0.00      0.00        11\n         mel       0.00      0.00      0.00       112\n          nv       0.67      1.00      0.80       671\n        vasc       0.00      0.00      0.00        14\n\n    accuracy                           0.67      1002\n   macro avg       0.10      0.14      0.11      1002\nweighted avg       0.45      0.67      0.54      1002\n\n\nEvaluating model: EfficientNetB0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 303ms/step\n              precision    recall  f1-score   support\n\n       akiec       0.70      0.50      0.58        32\n         bcc       0.80      0.54      0.64        52\n         bkl       0.70      0.82      0.75       110\n          df       0.62      0.45      0.53        11\n         mel       0.61      0.65      0.63       112\n          nv       0.93      0.93      0.93       671\n        vasc       0.65      0.79      0.71        14\n\n    accuracy                           0.85      1002\n   macro avg       0.72      0.67      0.68      1002\nweighted avg       0.85      0.85      0.84      1002\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"            Model  Accuracy  Weighted F1\n0        ResNet50  0.667665     0.536209\n1  EfficientNetB0  0.845309     0.843920","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Accuracy</th>\n      <th>Weighted F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ResNet50</td>\n      <td>0.667665</td>\n      <td>0.536209</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>EfficientNetB0</td>\n      <td>0.845309</td>\n      <td>0.843920</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 600x400 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":11},{"cell_type":"raw","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Section L: Confusion Matrices for ResNet50 and EfficientNetB0","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\n# Helper to plot confusion matrix\ndef plot_conf_matrix(y_true, y_pred, model_name):\n    cm = confusion_matrix(y_true, y_pred)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_names)\n    disp.plot(cmap='Blues', xticks_rotation=45)\n    plt.title(f\"{model_name} - Confusion Matrix\")\n    plt.grid(False)\n    plt.show()\n\n# Evaluate ResNet50\nresnet = build_resnet(unfreeze_last_blocks=2)\nresnet.load_weights(\"resnet_ft.h5\")\nresnet_preds = resnet.predict(test_it).argmax(axis=1)\nplot_conf_matrix(test_it.classes, resnet_preds, \"ResNet50\")\n\n# Evaluate EfficientNetB0\neff = build_efficientnet(unfreeze_last_blocks=2)\neff.load_weights(\"eff_ft.h5\")\neff_preds = eff.predict(test_it).argmax(axis=1)\nplot_conf_matrix(test_it.classes, eff_preds, \"EfficientNetB0\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Section M: Unseen images test\nLoad images, preprocess them, and classify them using both trained models.","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import load_img, img_to_array\n\n# Paths to new test images\nexternal_files = [f\"t{i}.jpg\" for i in range(1, 7)]\n\n# Load and preprocess a single image\ndef prepare_external_image(path, for_efficientnet=False):\n    img = load_img(path, target_size=(IMG_SIZE, IMG_SIZE))\n    img_arr = img_to_array(img)\n    img_arr = np.expand_dims(img_arr, axis=0)\n    if for_efficientnet:\n        img_arr = preprocess_input(img_arr)\n    else:\n        img_arr = img_arr / 255.0\n    return img_arr\n\n# Make predictions with both models\nprint(\"Predictions on External Images:\")\nfor file in external_files:\n    img_resnet = prepare_external_image(file, for_efficientnet=False)\n    img_eff = prepare_external_image(file, for_efficientnet=True)\n\n    pred_resnet = resnet.predict(img_resnet).argmax(axis=1)[0]\n    pred_eff = eff.predict(img_eff).argmax(axis=1)[0]\n\n    label_resnet = inv_map[pred_resnet]\n    label_eff = inv_map[pred_eff]\n\n    print(f\"{file}: ResNet50 → {label_resnet} | EfficientNetB0 → {label_eff}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}